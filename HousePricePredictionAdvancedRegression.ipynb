{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c44f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3859e849",
   "metadata": {},
   "source": [
    "### Step 1:  Inspecting the Dataframe for understanding provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75df1c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the file\n",
    "df=pd.read_csv('E:/IIITB_Upgrad_AI_ML_Course/AdvancedLinearRegression/HousepricingAssignment/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking size of the data\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking data types of columns and null value analysis if any\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6cb4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display basic statistical information for the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bf01bf",
   "metadata": {},
   "source": [
    "### Step 2: Data Cleansing Process -> Handling null & missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c7bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any missing values are present in the data\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89cd737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the column names that have missing values\n",
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4f4444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the amount of missing values in the columns\n",
    "columns_nan =  df.columns[df.isnull().any()]\n",
    "\n",
    "for col in columns_nan:\n",
    "    print(col, df[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the percentage of missing data to make decisions on working with the missing data\n",
    "nullval = pd.DataFrame(round(df.isnull().sum()/len(df.index)*100,2).sort_values(ascending=False),columns=[\"Null values in %\"])\n",
    "nullval.index.name = 'Feature names'\n",
    "nullval.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f4c462",
   "metadata": {},
   "source": [
    "#### Observations:we will drop the 'PoolQC','MiscFeature','Alley','Fence','FireplaceQu'column because there are so many missing values and id column is not required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58226e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['PoolQC','MiscFeature','Id','Alley','Fence','FireplaceQu'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326a5e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "null = pd.DataFrame(round(df.isnull().sum()/len(df.index)*100,2).sort_values(ascending=False),columns=[\"Null %\"])\n",
    "null.index.name = 'Features'\n",
    "null_df = null[null[\"Null %\"] > 0]\n",
    "null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c58cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710ddb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7884ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical columns\n",
    "df.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6652cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric columns\n",
    "df.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e53b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the columns with highest percentage of missing values\n",
    "print('The unique values in columsn with highest number if nan or missing values')\n",
    "print('\\n')\n",
    "print('LotFrontage: ',df['LotFrontage'].value_counts())\n",
    "print('\\n')\n",
    "print('GarageCond: ',df['GarageCond'].value_counts())\n",
    "print('\\n')\n",
    "print('GarageType: ',df['GarageType'].value_counts())\n",
    "print('\\n')\n",
    "print('GarageYrBlt: ',df['GarageYrBlt'].value_counts())\n",
    "print('\\n')\n",
    "print('GarageFinish: ',df['GarageFinish'].value_counts())\n",
    "print('\\n')\n",
    "print('GarageQual: ',df['GarageQual'].value_counts())\n",
    "print('\\n')\n",
    "print('BsmtExposure: ',df['BsmtExposure'].value_counts())\n",
    "print('\\n')\n",
    "print('BsmtFinType2: ',df['BsmtFinType2'].value_counts())\n",
    "print('\\n')\n",
    "print('BsmtFinType1: ',df['BsmtFinType1'].value_counts())\n",
    "print('\\n')\n",
    "print('BsmtCond: ',df['BsmtCond'].value_counts())\n",
    "print('\\n')\n",
    "print('BsmtQual: ',df['BsmtQual'].value_counts())\n",
    "print('\\n')\n",
    "print('MasVnrArea: ',df['MasVnrArea'].value_counts())\n",
    "print('\\n')\n",
    "print('MasVnrType: ',df['MasVnrType'].value_counts())\n",
    "print('\\n')\n",
    "print('Electrical: ',df['Electrical'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for outlier in the numerical columns\n",
    "df.describe(percentiles=[.25,.5,.75,.90,.95,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e365130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for the LotFrontage column and GarageYrBlt we will impute the missing values with the median since the feature contains outliers\n",
    "df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].median())\n",
    "\n",
    "df['GarageYrBlt'] = df['GarageYrBlt'].fillna(df['GarageYrBlt'].median())\n",
    "\n",
    "# for the \"below columns\" we will impute the null values with 'mode'\n",
    "for col in ('GarageCond', 'GarageType', 'GarageFinish','GarageQual'):\n",
    "    \n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "# for the \"Bsmt\" columns we will impute the null values with 'mode'\n",
    "for col in ('BsmtExposure', 'BsmtFinType2', 'BsmtFinType1','BsmtCond','BsmtQual'):\n",
    "    \n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "# for the columns we will impute the null values with 'mode'\n",
    "\n",
    "for col in ('MasVnrArea', 'MasVnrType', 'Electrical'):\n",
    "    \n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727ae64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "null = pd.DataFrame(round(df.isnull().sum()/len(df.index)*100,2).sort_values(ascending=False),columns=[\"Null %\"])\n",
    "null.index.name = 'Features'\n",
    "null_df = null[null[\"Null %\"] > 0]\n",
    "null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeac0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for the presence of any more null values\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f48c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Null value\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd384849",
   "metadata": {},
   "source": [
    "#### Observation: Data is clean and filled with related values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f72b3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8bd31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9769abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['PoolArea'].value_counts())\n",
    "print(df['MiscVal'].value_counts())\n",
    "print(df['3SsnPorch'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd4f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will drop these columns as it dominated by one value and it won't add any extra information to our model\n",
    "df = df.drop(['PoolArea','MiscVal','3SsnPorch'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798a4da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e72fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a15eba0",
   "metadata": {},
   "source": [
    "### Step 3: EDA - Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea23a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation map to see how features are correlated with SalePrice\n",
    "corrmat = df.corr()\n",
    "plt.subplots(figsize=(12,9))\n",
    "sns.heatmap(corrmat, vmax=0.9, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15382408",
   "metadata": {},
   "source": [
    "#### From the above we can see that some of the numerical colums are highly related with the sales price\n",
    "- LotFrontage\n",
    "- Overall Quality\n",
    "- Year Built\n",
    "- Year removeadd\n",
    "- MasVnrArea\n",
    "- TotalBsmn SF\n",
    "- 1st Foor SF\n",
    "- Gr ving Area\n",
    "- Fullbath\n",
    "- Fireplaces\n",
    "- Garage Area\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfc5712",
   "metadata": {},
   "source": [
    "#### We will retain them in our consideration during model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee308239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR to remove the outlier\n",
    "cols = ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', \n",
    "         'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF',\n",
    "        '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', \n",
    "        'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
    "        'EnclosedPorch','ScreenPorch', 'MoSold', 'YrSold', 'SalePrice'] # one or more\n",
    "\n",
    "Q1 = df[cols].quantile(0.05)\n",
    "Q3 = df[cols].quantile(0.95)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df = df[~((df[cols] < (Q1 - 1.5 * IQR)) |(df[cols] > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455bb3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a540c26",
   "metadata": {},
   "source": [
    "#### Let us also check what are the most corelated values present in the data from provided features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bd8c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "cm = np.corrcoef(df[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd25e172",
   "metadata": {},
   "source": [
    "#### We can see from the above chart that the top 10 variables are similar to what we had initially deciphered\n",
    "- OverallQual - It is obvious that having a good quality house would fetch bigger price\n",
    "- Grlivarea - More the area of the floor above the ground floor, greater is the price\n",
    "- Garage cars, garage area, total basement SF, 1st floor SF -Seems to make sense "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c1ec9",
   "metadata": {},
   "source": [
    "#### Plot graphs between some of these important numerical variables and see if we see any pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4116074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the same with a pairplot \n",
    "sns.set()\n",
    "cols = ['SalePrice', 'GrLivArea', 'GarageCars', 'BsmtUnfSF', 'BsmtFinSF1', 'GarageArea', 'TotalBsmtSF', 'YearBuilt', 'TotRmsAbvGrd', 'GarageYrBlt']\n",
    "sns.pairplot(df[cols], size = 2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b7243",
   "metadata": {},
   "source": [
    "##### Drop columns that are correlated and not contributing to 'SalePrice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf4a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['GarageCars'], axis = 1)\n",
    "df = df.drop(['BsmtUnfSF'], axis = 1)\n",
    "df = df.drop(['TotRmsAbvGrd'], axis = 1)\n",
    "df = df.drop(['GarageYrBlt'], axis = 1)    \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a85dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc9ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sale columns\n",
    "plt.figure()\n",
    "sns.distplot(df['SalePrice'],color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a916f",
   "metadata": {},
   "source": [
    "#### Target variable 'sale Price' vs a few select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada45f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse some important numeric columns\n",
    "sns.jointplot(x='GrLivArea', y='SalePrice', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2e60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lot frontage vs SalePrice \n",
    "sns.jointplot(x = df['LotFrontage'], y = df['SalePrice'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2565486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LotArea vs SalePrice\n",
    "sns.jointplot(x = df['LotArea'], y = df['SalePrice'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80d8d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1stFlrSF vs SalePrice\n",
    "sns.jointplot(x = df['1stFlrSF'], y = df['SalePrice'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66180f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ndFlrSF vs SalePrice\n",
    "sns.jointplot(x = df['2ndFlrSF'], y = df['SalePrice'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0220e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OverallQual vs SalePrice\n",
    "sns.jointplot(x = df['OverallQual'], y = df['SalePrice'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d01c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OverallCond vs SalePrice\n",
    "sns.jointplot(x=df['OverallCond'], y = df['SalePrice'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70482932",
   "metadata": {},
   "source": [
    "#### Observation: \n",
    " - Increase in the overall quality has a direct positive effect on the sale price.\n",
    " - Ground or First level houses i.e. '0' second floor Sq.Ft has also a steady increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98119166",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f4fdec",
   "metadata": {},
   "source": [
    "#### We can derive a column for 'Age of the property' when it was sold: Name it as 'PropAge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99339578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PropAge -  Property Age from yearsold - yearbuilt\n",
    "df['PropAge'] = (df['YrSold'] - df['YearBuilt'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e08f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PropAge vs SalePrice\n",
    "sns.jointplot(x = df['PropAge'], y = df['SalePrice'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1367701a",
   "metadata": {},
   "source": [
    "#### Observatons:\n",
    " - Increase in Property Age shows a decreasing saleprice trend i.e newer the property, high is the value\n",
    " -  We can drop the column Month sold and Year Sold, Year built and Year remodelled since it will not be required further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa599d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32620685",
   "metadata": {},
   "source": [
    "#### Handling of Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56f40cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical columns\n",
    "df.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a353d0e",
   "metadata": {},
   "source": [
    "#### Analyzing Categorical Data for presence of Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7f90bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualitative = [f for f in df.columns if df.dtypes[f] == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e40ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in qualitative:\n",
    "    df[c] = df[c].astype('category')\n",
    "    if df[c].isnull().any():\n",
    "        df[c] = df[c].cat.add_categories(['MISSING'])\n",
    "        df[c] = df[c].fillna('MISSING')\n",
    "\n",
    "def boxplot(x, y, **kwargs):\n",
    "    sns.boxplot(x=x, y=y)\n",
    "    x=plt.xticks(rotation=90)\n",
    "f = pd.melt(df, id_vars=['SalePrice'], value_vars=qualitative)\n",
    "g = sns.FacetGrid(f, col=\"variable\",  col_wrap=2, sharex=False, sharey=False, height=5)\n",
    "g = g.map(boxplot, \"value\", \"SalePrice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d773bb4b",
   "metadata": {},
   "source": [
    "#### Observation: Most of these variables have a diverse relationship with the 'Sales' and we will try to define some of them below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2fa6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova(frame):\n",
    "    anv = pd.DataFrame()\n",
    "    anv['feature'] = qualitative\n",
    "    pvals = []\n",
    "    for c in qualitative:\n",
    "        samples = []\n",
    "        for cls in frame[c].unique():\n",
    "            s = frame[frame[c] == cls]['SalePrice'].values\n",
    "            samples.append(s)\n",
    "        pval = stats.f_oneway(*samples)[1]\n",
    "        pvals.append(pval)\n",
    "    anv['pval'] = pvals\n",
    "    return anv.sort_values('pval')\n",
    "\n",
    "a = anova(df)\n",
    "a['disparity'] = np.log(1./a['pval'].values)\n",
    "sns.barplot(data=a, x='feature', y='disparity')\n",
    "x=plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca401efb",
   "metadata": {},
   "source": [
    "#### Observation:From the above chart we can see that some of the majorly influencing variables are -\n",
    "- Neighbourhood\n",
    "- ExterQuality\n",
    "- Basement Quality\n",
    "- KitchenQuality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85dcc00",
   "metadata": {},
   "source": [
    "### Step 4: Data preparation for Model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical value into Dummy variable\n",
    "df=pd.get_dummies(df,drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f8a0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing response variable from the set\n",
    "y = df.pop('SalePrice')\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09055cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train_test_split to split the data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084c5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "X_train, X_test, y_train,  y_test = train_test_split(X, y, \n",
    "                                                    train_size=0.7,\n",
    "                                                    test_size = 0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddcab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcce5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for no. of rows and columns in Train and Test data\n",
    "print('X_train shape',X_train.shape)\n",
    "print('X_test shape',X_test.shape)\n",
    "print('y_train shape',y_train.shape)\n",
    "print('y_test shape',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee477193",
   "metadata": {},
   "source": [
    "##### Scaling of numeric varaibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df157a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff722520",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d370c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f8c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to be scaled\n",
    "X_train.select_dtypes(include=['int64','int32','float64','float32']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bb6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_vars= ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',  \n",
    "           'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'TotalBsmtSF', \n",
    "           '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
    "           'BedroomAbvGr', 'KitchenAbvGr', 'Fireplaces', 'GarageArea',\n",
    "           'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', 'ScreenPorch']\n",
    "X_train[num_vars].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62313af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853fb171",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c85e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling using MinMax\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "#scaler = StandardScaler()\n",
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8310bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[num_vars] = scaler.fit_transform(X_train[num_vars])\n",
    "X_test[num_vars] = scaler.transform(X_test[num_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb76d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59760618",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545dde57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5463fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb22c0",
   "metadata": {},
   "source": [
    "### Step 5: Model Building and Evaluation Phase Starts\n",
    "\n",
    "##### Objective(s) are to generate model(s) with /  without RFE data set and evaluate model peformance.\n",
    "\n",
    " - Create linear regression model.\n",
    " - Use Ridge and Lasso\n",
    " - Compare to represent final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9240bf",
   "metadata": {},
   "source": [
    "##### 5.1.  Linear Regression model on Train data set without RFE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a00bd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25da616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression on features without RFE\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# Running RFE for further model evaluation on train data with RFE columns\n",
    "# Since there are more than 200 variables for analysis, we will run RFE to select some that have high predictive power\n",
    "# running RFE for top 100 variables\n",
    "rfe = RFE(lm, n_features_to_select=100)   \n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5c7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place holder for columns with good score of RFE\n",
    "col = X_train.columns[rfe.support_]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b558dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns may not be considered for model evaluation using RFE\n",
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f1b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating related rfe dataframe(s) with RFE selected variables\n",
    "X_train_rfe=X_train[col]\n",
    "X_test_rfe=X_test[col]\n",
    "print(X_train_rfe.shape)\n",
    "print(X_test_rfe.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c09f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe = pd.DataFrame(X_train[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e858d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coefficients and intercept\n",
    "print(lm.intercept_)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce1555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the ranks\n",
    "list(zip(X_train.columns,rfe.support_,rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1caf087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries for model evalution\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca86c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r2score,RSS and RMSE for Linear regression model without RFE Columns inclusion.\n",
    "y_pred_train = lm.predict(X_train)\n",
    "y_pred_test = lm.predict(X_test)\n",
    "\n",
    "metric = []\n",
    "r2_train_lr = r2_score(y_train, y_pred_train)\n",
    "print('r2 train: ', r2_train_lr)\n",
    "metric.append(r2_train_lr)\n",
    "\n",
    "r2_test_lr = r2_score(y_test, y_pred_test)\n",
    "print('r2 test: ',r2_test_lr)\n",
    "metric.append(r2_test_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_train - y_pred_train))\n",
    "print('rss1: ',rss1_lr)\n",
    "metric.append(rss1_lr)\n",
    "\n",
    "rss2_lr = np.sum(np.square(y_test - y_pred_test))\n",
    "print('rss2: ',rss2_lr)\n",
    "metric.append(rss2_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_train)\n",
    "print('MSE train: ',mse_train_lr)\n",
    "metric.append(mse_train_lr**0.5)\n",
    "\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_test)\n",
    "print('MSE test: ',mse_test_lr)\n",
    "metric.append(mse_test_lr**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55ae6e8",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    " - The Linear model without RFE for Test data is Overfitting.\n",
    " - Generated R2 score for Test is negative.\n",
    " \n",
    "##### In the following step, Ridge and Lasso are applied to compare the result by using Train data set not having columns from RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c7aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd4f4a3",
   "metadata": {},
   "source": [
    "##### 5.2.  Using  Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a36326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of hyperparameter values or alphas to tune\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n",
    "\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "# cross validation\n",
    "folds = 5\n",
    "ridge_model_cv = GridSearchCV(estimator = ridge, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = folds, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1)            \n",
    "ridge_model_cv.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d95c40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the best hyperparameter alpha\n",
    "print(ridge_model_cv.best_params_)\n",
    "print(ridge_model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19677273",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 3\n",
    "ridge = Ridge(alpha=alpha)\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c0431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets calculate some metrics such as R2 score, RSS and RMSE\n",
    "y_pred_train = ridge.predict(X_train)\n",
    "y_pred_test = ridge.predict(X_test)\n",
    "\n",
    "metric2 = []\n",
    "r2_train_lr = r2_score(y_train, y_pred_train)\n",
    "print('r2 train: ', r2_train_lr)\n",
    "metric2.append(r2_train_lr)\n",
    "\n",
    "r2_test_lr = r2_score(y_test, y_pred_test)\n",
    "print('r2 test: ',r2_test_lr)\n",
    "metric2.append(r2_test_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_train - y_pred_train))\n",
    "print('rss1: ',rss1_lr)\n",
    "metric2.append(rss1_lr)\n",
    "\n",
    "rss2_lr = np.sum(np.square(y_test - y_pred_test))\n",
    "print('rss2: ',rss2_lr)\n",
    "metric2.append(rss2_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_train)\n",
    "print('MSE train: ',mse_train_lr)\n",
    "metric2.append(mse_train_lr**0.5)\n",
    "\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_test)\n",
    "print('MSE test: ',mse_test_lr)\n",
    "metric2.append(mse_test_lr**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0152b3d9",
   "metadata": {},
   "source": [
    "##### Observations: \n",
    " - The above Ridge model score better than the non-regularised version seen above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbfa7f3",
   "metadata": {},
   "source": [
    "#### 5.2.  Using  Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da13c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of Hyperparameter values or  alphas to tune\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n",
    "\n",
    "GridSearchCV(cv=5, estimator=Lasso(),\n",
    "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3,\n",
    "                                   0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0,\n",
    "                                   4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50,\n",
    "                                   100, 500, 1000]},\n",
    "             return_train_score=True, scoring='neg_mean_absolute_error',\n",
    "             verbose=1)\n",
    "lasso = Lasso()\n",
    "\n",
    "## Lasso regression auto selects important features.\n",
    "# cross validation\n",
    "lasso_model_cv = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = folds, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1)            \n",
    "\n",
    "lasso_model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1801e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for best hyperparameter alpha value.\n",
    "print(lasso_model_cv.best_params_)\n",
    "print(lasso_model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ca6a08",
   "metadata": {},
   "source": [
    "##### The optimum value of alpha is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e652f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha =100\n",
    "\n",
    "lasso = Lasso(alpha=alpha)\n",
    "        \n",
    "lasso.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e03afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3995ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets calculate some metrics such as R2 score, RSS and RMSE\n",
    "\n",
    "y_pred_train = lasso.predict(X_train)\n",
    "y_pred_test = lasso.predict(X_test)\n",
    "\n",
    "metric3 = []\n",
    "r2_train_lr = r2_score(y_train, y_pred_train)\n",
    "print('r2 train: ', r2_train_lr)\n",
    "metric3.append(r2_train_lr)\n",
    "\n",
    "r2_test_lr = r2_score(y_test, y_pred_test)\n",
    "print('r2 test: ',r2_test_lr)\n",
    "metric3.append(r2_test_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_train - y_pred_train))\n",
    "print('rss1: ',rss1_lr)\n",
    "metric3.append(rss1_lr)\n",
    "\n",
    "rss2_lr = np.sum(np.square(y_test - y_pred_test))\n",
    "print('rss2: ',rss2_lr)\n",
    "metric3.append(rss2_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_train)\n",
    "print('MSE train: ',mse_train_lr)\n",
    "metric3.append(mse_train_lr**0.5)\n",
    "\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_test)\n",
    "print('MSE test: ',mse_test_lr)\n",
    "metric3.append(mse_test_lr**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43afc8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a table which contain all the metrics\n",
    "\n",
    "lr_table = {'Metric': ['R2 Score (Train)','R2 Score (Test)','RSS (Train)','RSS (Test)',\n",
    "                       'MSE (Train)','MSE (Test)'], \n",
    "        'Linear Regression': metric\n",
    "        }\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "lr_metric = pd.DataFrame(lr_table ,columns = ['Metric', 'Linear Regression'] )\n",
    "\n",
    "rg_metric = pd.Series(metric2, name = 'Ridge Regression')\n",
    "ls_metric = pd.Series(metric3, name = 'Lasso Regression')\n",
    "\n",
    "final_metric = pd.concat([lr_metric, rg_metric, ls_metric], axis = 1)\n",
    "\n",
    "final_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a991c0ec",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "  - Both Ridge and Lasso produce a better performing model, with Lasso outperforming Ridge slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47696fe2",
   "metadata": {},
   "source": [
    "#### 5.3 Predictions and Normality of Residuals with columns not having RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b8e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using predictions generated by ridge method.\n",
    "ridge_pred = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e036c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting y_test and y_pred to understand the spread for ridge regression.\n",
    "fig = plt.figure(dpi=100)\n",
    "plt.scatter(y_test,ridge_pred)\n",
    "fig.suptitle('y_test vs ridge_pred', fontsize=20)              # Plot heading \n",
    "plt.xlabel('y_test', fontsize=18)                          # X-label\n",
    "plt.ylabel('ridge_pred', fontsize=16)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c631b6b3",
   "metadata": {},
   "source": [
    "##### Observation(s): \n",
    " - The graph depicts that there is a linear regression model which can be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c88abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res=y_test-ridge_pred\n",
    "# Distribution of errors\n",
    "sns.distplot(y_res,kde=True)\n",
    "plt.title('Normality of error terms/residuals Ridge')\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b14a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using predictions generated by lasso method.\n",
    "lasso_pred = lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd0d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting y_test and y_pred to understand the spread for lasso regression.\n",
    "fig = plt.figure(dpi=100)\n",
    "plt.scatter(y_test,lasso_pred)\n",
    "fig.suptitle('y_test vs lasso_pred', fontsize=20)              # Plot heading \n",
    "plt.xlabel('y_test', fontsize=18)                          # X-label\n",
    "plt.ylabel('lasso_pred', fontsize=16)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1351e0c2",
   "metadata": {},
   "source": [
    "##### Observation(s): \n",
    " - The graph depicts that there is a linear regression model similar to ridge with slight variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b378995",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res=y_test-lasso_pred\n",
    "# Distribution of errors\n",
    "sns.distplot(y_res,kde=True)\n",
    "plt.title('Normality of error terms/residuals Lasso')\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99c2f19",
   "metadata": {},
   "source": [
    "####  5.4 Check for Changes in Coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1514e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = pd.DataFrame(index=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5aabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas.rows = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183264a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas['Linear'] = lm.coef_\n",
    "betas['Ridge'] = ridge.coef_\n",
    "betas['Lasso'] = lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed9b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "betas.head(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573199de",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = pd.DataFrame(index=X_train.columns)\n",
    "betas.rows = X_train.columns\n",
    "betas['Lasso'] = lasso.coef_\n",
    "betas.head(70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f693e17",
   "metadata": {},
   "source": [
    "#### 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f514dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression on features on columns generated with RFE\n",
    "lm_rfe=LinearRegression()\n",
    "\n",
    "lm_rfe.fit(X_train_rfe,y_train)\n",
    "\n",
    "y_pred_train = lm_rfe.predict(X_train_rfe)\n",
    "y_pred_test = lm_rfe.predict(X_test_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd0a7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r2score,RSS and RMSE\n",
    "y_pred_train = lm_rfe.predict(X_train_rfe)\n",
    "y_pred_test = lm_rfe.predict(X_test_rfe)\n",
    "\n",
    "metric = []\n",
    "r2_train_lr = r2_score(y_train, y_pred_train)\n",
    "print('r2 train: ', r2_train_lr)\n",
    "metric.append(r2_train_lr)\n",
    "\n",
    "r2_test_lr = r2_score(y_test, y_pred_test)\n",
    "print('r2 test: ',r2_test_lr)\n",
    "metric.append(r2_test_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_train - y_pred_train))\n",
    "print('rss1: ',rss1_lr)\n",
    "metric.append(rss1_lr)\n",
    "\n",
    "rss2_lr = np.sum(np.square(y_test - y_pred_test))\n",
    "print('rss2: ',rss2_lr)\n",
    "metric.append(rss2_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_train)\n",
    "print('MSE train: ',mse_train_lr)\n",
    "metric.append(mse_train_lr**0.5)\n",
    "\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_test)\n",
    "print('MSE test: ',mse_test_lr)\n",
    "metric.append(mse_test_lr**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5209392a",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    " - The Linear model provides R2 Test score value in terms of negative which is highly overfitting. \n",
    "  - R2 is negative only when the chosen model does not follow the trend of provided data.\n",
    "  - Fit is worse than a horizontal linear and generated model is highly problematic.\n",
    "  - It shows a high score in the training data, but this will be due to the model learning the data and overfitting on the training data. \n",
    "##### In the following step, Ridge and Lasso are applied to compare the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edeb218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of alphas to tune\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n",
    "\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "# cross validation\n",
    "folds = 5\n",
    "ridge_model_cv = GridSearchCV(estimator = ridge, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = folds, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1)            \n",
    "ridge_model_cv.fit(X_train_rfe, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f70690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the best hyperparameter alpha\n",
    "print(ridge_model_cv.best_params_)\n",
    "print(ridge_model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525fe1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "ridge = Ridge(alpha=alpha)\n",
    "ridge.fit(X_train_rfe, y_train)\n",
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a4a4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r2score,RSS and RMSE\n",
    "y_pred_train = ridge.predict(X_train_rfe)\n",
    "y_pred_test = ridge.predict(X_test_rfe)\n",
    "\n",
    "metric = []\n",
    "r2_train_lr = r2_score(y_train, y_pred_train)\n",
    "print('r2 train: ', r2_train_lr)\n",
    "metric.append(r2_train_lr)\n",
    "\n",
    "r2_test_lr = r2_score(y_test, y_pred_test)\n",
    "print('r2 test: ',r2_test_lr)\n",
    "metric.append(r2_test_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_train - y_pred_train))\n",
    "print('rss1: ',rss1_lr)\n",
    "metric.append(rss1_lr)\n",
    "\n",
    "rss2_lr = np.sum(np.square(y_test - y_pred_test))\n",
    "print('rss2: ',rss2_lr)\n",
    "metric.append(rss2_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_train)\n",
    "print('MSE train: ',mse_train_lr)\n",
    "metric.append(mse_train_lr**0.5)\n",
    "\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_test)\n",
    "print('MSE test: ',mse_test_lr)\n",
    "metric.append(mse_test_lr**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ead24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of alphas to tune\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n",
    "\n",
    "GridSearchCV(cv=5, estimator=Lasso(),\n",
    "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3,\n",
    "                                   0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0,\n",
    "                                   4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50,\n",
    "                                   100, 500, 1000]},\n",
    "             return_train_score=True, scoring='neg_mean_absolute_error',\n",
    "             verbose=1)\n",
    "lasso = Lasso()\n",
    "\n",
    "## Lasso regression auto selects important features.\n",
    "# cross validation\n",
    "lasso_model_cv = GridSearchCV(estimator = lasso, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error', \n",
    "                        cv = folds, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1)            \n",
    "\n",
    "lasso_model_cv.fit(X_train_rfe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f5fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lasso_model_cv.best_params_)\n",
    "print(lasso_model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b12d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha =8\n",
    "\n",
    "lasso = Lasso(alpha=alpha)\n",
    "        \n",
    "lasso.fit(X_train_rfe, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627be97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets calculate some metrics such as R2 score, RSS and RMSE\n",
    "\n",
    "y_pred_train = lasso.predict(X_train_rfe)\n",
    "y_pred_test = lasso.predict(X_test_rfe)\n",
    "\n",
    "metric3 = []\n",
    "r2_train_lr = r2_score(y_train, y_pred_train)\n",
    "print('r2 train: ', r2_train_lr)\n",
    "metric3.append(r2_train_lr)\n",
    "\n",
    "r2_test_lr = r2_score(y_test, y_pred_test)\n",
    "print('r2 test: ',r2_test_lr)\n",
    "metric3.append(r2_test_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_train - y_pred_train))\n",
    "print('rss1: ',rss1_lr)\n",
    "metric3.append(rss1_lr)\n",
    "\n",
    "rss2_lr = np.sum(np.square(y_test - y_pred_test))\n",
    "print('rss2: ',rss2_lr)\n",
    "metric3.append(rss2_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_train)\n",
    "print('MSE train: ',mse_train_lr)\n",
    "metric3.append(mse_train_lr**0.5)\n",
    "\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_test)\n",
    "print('MSE test: ',mse_test_lr)\n",
    "metric3.append(mse_test_lr**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0299411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a table which contain all the metrics\n",
    "\n",
    "lr_table = {'Metric': ['R2 Score (Train)','R2 Score (Test)','RSS (Train)','RSS (Test)',\n",
    "                       'MSE (Train)','MSE (Test)'], \n",
    "        'Linear Regression': metric\n",
    "        }\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "lr_metric = pd.DataFrame(lr_table ,columns = ['Metric', 'Linear Regression'] )\n",
    "\n",
    "rg_metric = pd.Series(metric2, name = 'Ridge Regression')\n",
    "ls_metric = pd.Series(metric3, name = 'Lasso Regression')\n",
    "\n",
    "final_metric = pd.concat([lr_metric, rg_metric, ls_metric], axis = 1)\n",
    "\n",
    "final_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96e41d",
   "metadata": {},
   "source": [
    "#### 6.1 Predictions and Normality of Residuals with columns generaed using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706f7c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pred_rfe = ridge.predict(X_test_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d093fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting y_test and y_pred to understand the spread for ridge regression.\n",
    "fig = plt.figure(dpi=100)\n",
    "plt.scatter(y_test,ridge_pred_rfe)\n",
    "fig.suptitle('y_test vs ridge_pred', fontsize=20)              # Plot heading \n",
    "plt.xlabel('y_test', fontsize=18)                          # X-label\n",
    "plt.ylabel('ridge_pred', fontsize=16)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7041e80f",
   "metadata": {},
   "source": [
    "##### Observation(s): \n",
    " - The graph depicts that there is a linear regression model which can be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028ca56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res=y_test-ridge_pred_rfe\n",
    "# Distribution of errors\n",
    "sns.distplot(y_res,kde=True)\n",
    "plt.title('Normality of error terms/residuals')\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8ac586",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_pred_rfe = lasso.predict(X_test_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42db476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting y_test and y_pred to understand the spread for lasso regression.\n",
    "fig = plt.figure(dpi=100)\n",
    "plt.scatter(y_test,lasso_pred_rfe)\n",
    "fig.suptitle('y_test vs lasso_pred', fontsize=20)              # Plot heading \n",
    "plt.xlabel('y_test', fontsize=18)                          # X-label\n",
    "plt.ylabel('lasso_pred', fontsize=16)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d746e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res=y_test-lasso_pred_rfe\n",
    "# Distribution of errors\n",
    "sns.distplot(y_res,kde=True)\n",
    "plt.title('Normality of error terms/residuals')\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8233d213",
   "metadata": {},
   "source": [
    "####  6.2 Check for Changes in Coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240f6c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_rfe = pd.DataFrame(index=X_train_rfe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e82bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_rfe.rows = X_train_rfe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a67d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "betas_rfe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f6b42",
   "metadata": {},
   "source": [
    "#### 7. Subjective Questsions related analysis\n",
    " \n",
    "\n",
    "- Question 1: What happens if you double the ideal alpha value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b794d83e",
   "metadata": {},
   "source": [
    "#### Calculations for Ridge related :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best optimal hyper parameter considered during ridge regression model generation {'alpha': 3.0} without RFE\n",
    "# Doubling the value from 3 to 6\n",
    "alpha = 6\n",
    "ridge_Double = Ridge(alpha=alpha)\n",
    "ridge_Double.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8c5d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets calculate some metrics such as R2 score, RSS and RMSE\n",
    "y_pred_train = ridge_Double.predict(X_train)\n",
    "y_pred_test = ridge_Double.predict(X_test)\n",
    "\n",
    "metric2 = []\n",
    "r2_train_lr = r2_score(y_train, y_pred_train)\n",
    "print('r2 train: ', r2_train_lr)\n",
    "metric2.append(r2_train_lr)\n",
    "\n",
    "r2_test_lr = r2_score(y_test, y_pred_test)\n",
    "print('r2 test: ',r2_test_lr)\n",
    "metric2.append(r2_test_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_train - y_pred_train))\n",
    "print('rss1: ',rss1_lr)\n",
    "metric2.append(rss1_lr)\n",
    "\n",
    "rss2_lr = np.sum(np.square(y_test - y_pred_test))\n",
    "print('rss2: ',rss2_lr)\n",
    "metric2.append(rss2_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_train)\n",
    "print('MSE train: ',mse_train_lr)\n",
    "metric2.append(mse_train_lr**0.5)\n",
    "\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_test)\n",
    "print('MSE test: ',mse_test_lr)\n",
    "metric2.append(mse_test_lr**0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed604f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best optimal hyper parameter considered during ridge regression model generation {'alpha': 1.0} with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367ceef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doubling the value from 1 to 2.\n",
    "alpha = 2\n",
    "ridge_Double_rfe = Ridge(alpha=alpha)\n",
    "ridge_Double_rfe.fit(X_train_rfe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cfbe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets calculate some metrics such as R2 score, RSS and RMSE\n",
    "y_pred_train = ridge_Double_rfe.predict(X_train_rfe)\n",
    "y_pred_test = ridge_Double_rfe.predict(X_test_rfe)\n",
    "\n",
    "metric2 = []\n",
    "r2_train_lr = r2_score(y_train, y_pred_train)\n",
    "print('r2 train: ', r2_train_lr)\n",
    "metric2.append(r2_train_lr)\n",
    "\n",
    "r2_test_lr = r2_score(y_test, y_pred_test)\n",
    "print('r2 test: ',r2_test_lr)\n",
    "metric2.append(r2_test_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_train - y_pred_train))\n",
    "print('rss1: ',rss1_lr)\n",
    "metric2.append(rss1_lr)\n",
    "\n",
    "rss2_lr = np.sum(np.square(y_test - y_pred_test))\n",
    "print('rss2: ',rss2_lr)\n",
    "metric2.append(rss2_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_train)\n",
    "print('MSE train: ',mse_train_lr)\n",
    "metric2.append(mse_train_lr**0.5)\n",
    "\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_test)\n",
    "print('MSE test: ',mse_test_lr)\n",
    "metric2.append(mse_test_lr**0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e4eaf0",
   "metadata": {},
   "source": [
    "#### Observations : After doubling Ridge hyperparameter or Alpha value obtained with / without RFE\n",
    " \n",
    "  - In both cases alpha value has decreased R2 score slightly on training and slightly increased on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f702f9",
   "metadata": {},
   "source": [
    "#### Calculations for Lasso related :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e394dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best optimal hyper parameter considered during ridge regression model generation {'alpha': 100} without RFE\n",
    "# Doubling the value from 100 to 200\n",
    "\n",
    "alpha = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e48ae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lasso_Double = Lasso(alpha=alpha)\n",
    "        \n",
    "lasso_Double.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310aeccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets calculate some metrics such as R2 score, RSS and RMSE\n",
    "y_pred_train = lasso_Double.predict(X_train)\n",
    "y_pred_test = lasso_Double.predict(X_test)\n",
    "\n",
    "metric2 = []\n",
    "r2_train_lr = r2_score(y_train, y_pred_train)\n",
    "print('r2 train: ', r2_train_lr)\n",
    "metric2.append(r2_train_lr)\n",
    "\n",
    "r2_test_lr = r2_score(y_test, y_pred_test)\n",
    "print('r2 test: ',r2_test_lr)\n",
    "metric2.append(r2_test_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_train - y_pred_train))\n",
    "print('rss1: ',rss1_lr)\n",
    "metric2.append(rss1_lr)\n",
    "\n",
    "rss2_lr = np.sum(np.square(y_test - y_pred_test))\n",
    "print('rss2: ',rss2_lr)\n",
    "metric2.append(rss2_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_train)\n",
    "print('MSE train: ',mse_train_lr)\n",
    "metric2.append(mse_train_lr**0.5)\n",
    "\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_test)\n",
    "print('MSE test: ',mse_test_lr)\n",
    "metric2.append(mse_test_lr**0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6710d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best optimal hyper parameter considered during ridge regression model generation {'alpha': 8.0} with RFE\n",
    "\n",
    "# Doubling the value from 8 to 16.\n",
    "alpha = 16\n",
    "lasso_Double_rfe = Lasso(alpha=alpha)\n",
    "        \n",
    "lasso_Double_rfe.fit(X_train_rfe, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbc7b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets calculate some metrics such as R2 score, RSS and RMSE\n",
    "y_pred_train = lasso_Double_rfe.predict(X_train_rfe)\n",
    "y_pred_test = lasso_Double_rfe.predict(X_test_rfe)\n",
    "\n",
    "metric2 = []\n",
    "r2_train_lr = r2_score(y_train, y_pred_train)\n",
    "print('r2 train: ', r2_train_lr)\n",
    "metric2.append(r2_train_lr)\n",
    "\n",
    "r2_test_lr = r2_score(y_test, y_pred_test)\n",
    "print('r2 test: ',r2_test_lr)\n",
    "metric2.append(r2_test_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_train - y_pred_train))\n",
    "print('rss1: ',rss1_lr)\n",
    "metric2.append(rss1_lr)\n",
    "\n",
    "rss2_lr = np.sum(np.square(y_test - y_pred_test))\n",
    "print('rss2: ',rss2_lr)\n",
    "metric2.append(rss2_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_train)\n",
    "print('MSE train: ',mse_train_lr)\n",
    "metric2.append(mse_train_lr**0.5)\n",
    "\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_test)\n",
    "print('MSE test: ',mse_test_lr)\n",
    "metric2.append(mse_test_lr**0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac97dad",
   "metadata": {},
   "source": [
    "#### Observations : After doubling Lasso hyperparameter or Alpha value obtained with / without RFE\n",
    " \n",
    "  - In both cases alpha value has decreased R2 score slightly on training and increased on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a66e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking out important predictor variables\n",
    "beta_vals = pd.DataFrame(index=X_train_rfe.columns)\n",
    "beta_vals.rows = X_train_rfe.columns\n",
    "beta_vals['ridge_Double_rfe'] = ridge_Double_rfe.coef_\n",
    "beta_vals['Ridge'] = ridge.coef_\n",
    "beta_vals['Lasso'] = lasso.coef_\n",
    "beta_vals['lasso_Double_rfe'] = lasso_Double_rfe.coef_\n",
    "pd.set_option('display.max_rows', None)\n",
    "beta_vals.head(70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cf1a95",
   "metadata": {},
   "source": [
    "##### Question 3\n",
    "- After building the model, you realised that the five most important predictor variables in the lasso model are not available in the incoming data. You will now have to create another model excluding the five most important predictor variables. Which are the five most important predictor variables now?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae926bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a9ce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79edd74",
   "metadata": {},
   "source": [
    "##### LotArea,OverallQual,YearBuilt,BsmtFinSF1,TotalBsmtSF are the top 5 important predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c6716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping top 5 columns\n",
    "X_train2 = X_train_rfe.drop(['LotArea','OverallQual','YearBuilt','BsmtFinSF1','TotalBsmtSF'],axis=1)\n",
    "X_test2 = X_test_rfe.drop(['LotArea','OverallQual','YearBuilt','BsmtFinSF1','TotalBsmtSF'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f52f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9098dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab2855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha 8\n",
    "alpha = 8\n",
    "lasso2_rfe = Lasso(alpha=alpha)\n",
    "lasso2_rfe.fit(X_train2, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d41af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets calculate some metrics such as R2 score, RSS and RMSE\n",
    "y_pred_train = lasso2_rfe.predict(X_train2)\n",
    "y_pred_test = lasso2_rfe.predict(X_test2)\n",
    "\n",
    "metric2 = []\n",
    "r2_train_lr = r2_score(y_train, y_pred_train)\n",
    "print('r2 train: ', r2_train_lr)\n",
    "metric2.append(r2_train_lr)\n",
    "\n",
    "r2_test_lr = r2_score(y_test, y_pred_test)\n",
    "print('r2 test: ',r2_test_lr)\n",
    "metric2.append(r2_test_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_train - y_pred_train))\n",
    "print('rss1: ',rss1_lr)\n",
    "metric2.append(rss1_lr)\n",
    "\n",
    "rss2_lr = np.sum(np.square(y_test - y_pred_test))\n",
    "print('rss2: ',rss2_lr)\n",
    "metric2.append(rss2_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_train, y_pred_train)\n",
    "print('MSE train: ',mse_train_lr)\n",
    "metric2.append(mse_train_lr**0.5)\n",
    "\n",
    "mse_test_lr = mean_squared_error(y_test, y_pred_test)\n",
    "print('MSE test: ',mse_test_lr)\n",
    "metric2.append(mse_test_lr**0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b275e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#important predictor variables\n",
    "betas = pd.DataFrame(index=X_train2.columns)\n",
    "betas.rows = X_train_rfe.columns\n",
    "betas['lasso2_rfe'] = lasso2_rfe.coef_\n",
    "pd.set_option('display.max_rows', None)\n",
    "betas.head(68)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e7e9ab",
   "metadata": {},
   "source": [
    " - 1stFlrSF\n",
    " - GrLivArea\n",
    " - Stree_Pave\n",
    " - RoofSyle_Shed\n",
    " - BsmtExposure_Gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0807656f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
